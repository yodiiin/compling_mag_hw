### Задание 1 (5 баллов).

Ответьте на следующие вопросы (по возможности своими словами, а не копипастой):

1. Приведите классификацию формальных грамматик Хомского с примерами для категорий 2 и 3.

    0) неограниченные грамматики
    1) контекстно-зависимые грамматики
    2) контекстно-свободные грамматики
        - Языки программирования, разработка компиляторов (синтаксических анализаторов); языки описания документов (HTML, XML). КС-языки распознает автомат с магазинной памятью (использует стек для хранения памяти, для чтения доступен только верхний элемент)
    3) регулярные языки
        - регулярные выражения: разные стандарты (IEEE POSIX: Basic RE, Extended RE; PCRE: Python, Java, JavaScript... (есть lookarounds; синтаксис взят из PERL))

2. Что такое бейзлайн, пайплайн, SOTA? Приведите примеры.

    Бейзлайн — самое простое, неидеальное, но гарантирующее какой-то промежуточный результат решение некоторой задачи, от которого можно отталкиваться, усложнять (=совершенствовать) модель для получения уже качественного результата. Например, в NLP бейзланом может служить модель bag-of-words, которая содержит информацию о частотности слов текста и может использоваться при классификации текстов (но она не супер крутая, если необходимо учесть какие-то другие характеристики, напр. порядок слов или грамматику, поэтому могут потребоваться более сложные алгоритмы обработки текста, но мешок слов может послужить некой отправной точкой).

    Пайплайн — этап решения какой-то задачи. Напр., для предобработки текста его нужно сначала поделить на токены, потом на предложения, потом их нужно как-то нормализовать (с помощью стемминга/лемматизации). Каждый из этих этапов является пайплайном.

    SOTA (State of the Art) — модель, которая в решении какой-то задачи показывает самые высокие результаты по метрикам, принимаемых в рамках решаемой задачи. Напр., сейчас (насколько я понимаю...) GPT-4 является SOTA среди языковых моделей.

3. Какие элементы имплементации регулярного языка PCRE не являются собственно элементами грамматики регулярного языка по классификации Хомского?

    1) проверки (lookaraounds)
    2) ссылки на группу (backreferences)
    3) ленивые квантификаторы (possessive quantifiers)

4. Что такое языковая модель? Какие типы языковых моделей вы знаете?

    Языковая модель — модель (программа), которая предсказывает вероятность появления слова в данном контексте и решает такие задачи, как поддержание диалога, генерация текста, предсказание слова в Т9, машинный перевод и т.п. 

    Типы: n-грамные, статистические (пораждающие), нейросетевые (supervised/unsupervised)


5. Чем задача классификации отличается от задачи кластеризации?

    При классификации объектов необходимы заранее заданные классы, по которым объекты будут распределяться; при кластеризации модель сама определяет признаки на основе данных, по которым объекты будут распределяться (по похожести друг на друга). Например, мы можем поставить задачу классификации текстов на определенные жанры, тогда нужно заранее определить, какими признаками должен обладать текст, чтобы отнести его к тому или иному жанру, а можно поставить задачу распределить тексты неизвестно по каким критериям, но так, что эти тексты сгруппируются между собой по каким-то признакам, которые сама машина определила в ходе обработки данных.
    

### Задание 2 (10 баллов). 

Попробуйте самостоятельно разработать метрики для оценки качества автоматического морфологического анализа: как бы вы оценивали качество лемматизации, приписывания частей речи и морфологических характеристик? Подумайте, какие вещи необходимо учесть. В результате у вас должны получиться три формулы, в которых будут фигурировать y_true (правильные ответы) и y_pred (предсказанные парсером ответы). Для морфологических признаков ответ явно будет складываться из нескольких категорий, например, род, число и падеж, нужно это учесть. Опишите словами ход своих рассуждений, приведите аргументы. Можно отталкиваться от уже существующих метрик, но если берете готовые, нужно их проанализировать.

    Посмотрев разные статьи, я решила использовать готовые метрики для анализа морфопарсера. Для удобства я распишу, что значит каждая из используемых переменнных (и введу несколько новых):

        y_true — всего правильных ответов
        y_pred — всего ответов парсера 
        y_pred_true = (y_true|y_pred) — правильно предсказанные парсером ответы
        y_total — общее кол-во анализируемых словоформ

    Для оценки лемматизации можно использовать точность (Accuracy), которая показывает отношение количества правильно лемматризированных слов к количеству всех анализируемых словоформ:

        Accuracy = y_pred_true / y_total
    
    Accuracy — самая простая метрика "в лоб", которую можно использовать для оценки качества алгоритма.
    
    Для оценки разметки частеречных тегов и приписывания морф.признаков Accuracy не совсем подойдет. По каким-то частям речи в наших данных может быть перевес, например, будет много существительных и глаголов, но очень мало прилагательных и наречий, и тогда возможна ситуация, при которой классификатор будет хорошо распознавать существительные и глаголы, но очень плохо будет справляться с прилагательными, а Accuracy будет относительно высоким (потому что у нас смешаются истинно положительные примеры с истинно отрицательными). То же самое получается относительно морф.признаков — по какому-то из признаков может быть перевес.

    Поэтому для оценки частеречной разметки и разметки морф.признаков будет лучше использовать точность (Precision) и полноту (Recall) для каждой из частей речи и морф.признака:

        Precision = y_pred_true / y_pred — кол-во правильных ответов парсера делим на общее кол-во ответов парсера (правильные + неправильные + случаи, когда парсер не определил слово к какому-то классу)

        Recall = y_pred_true / y_true — кол-во правильных ответов парсера делим на всего правильных ответов
    
    Еще для полной картины можно рассчитать F-меру для оценки pos-теггирования и приписывания морф.признаков. Если у нашей модели высокая точность, то может оказаться так, что полнота будет низкой (или наоборот). F-мера связывает полноту и точности, и будет уменьшаться при падении и полноты, и точности. F-мера — гармоническое среднее точности и полноты:

        F = 2 * (precision * recall) / precision + recall
    



### Задание 3 (10 баллов). 

Выберите любую понравившуюся вам задачу NLP и исследуйте литературу по этой задаче. Какой у нее бейзлайн? Какая SOTA? В каком направлении ведутся современные исследования, связанные с этой задачей? Какие практические применения? Напишите коротенький конспект. 

Рекомендация: попробуйте искать survey - статьи на scholar.google.com.

    Задача: разрешение кореферентности (Coreference resolution) — поиск всех упоминаний в тексте, которые относятся к одной и той же сущности. Задача разрешения кореферентности (и также разрешении анафоры) важна для таких более высокоуровневых задач и областей NLP, как машинный перевод, извлечение именованных сущностей, анализ сентиментальности, автоматическая суммаризация текста (в целом — там, где нам важно учитывать кореферентные связи между словами, чтобы понимать, в каком месте текста о чем говорится, я для себя понимаю это так...).
    Задача разрешение кореферентности — поделить множества упоминаний сущностей на кореферентные цепочки.
    
    Бейзлайн: одной из простейших ML-моделей, которую часто используют в качестве бейзлайна в рамках разреешния кореферентности, является модель "пара упоминаний" (mention-pair model) [Soon et al. 2001](https://aclanthology.org/J01-4004.pdf) — для каждой пары упоминаний (анафор + ИГ) нужно установить, входят ли они в одну кореферентую цепочку:
        - выделяются гипотетически кореферентные ИГ;
        - для каждой пары решается, явлются ли ИГ кореферентными;
        - если пары кореференты, они группируются в кореферентную цепочку (а кореферентые цепочки собираются в кластер упоминаний)

        Чтобы выделить эти пары упоминаний, устанавливаются признаки для ИГ, по которым классификатор будет отбирать пары. Набор признаков может варьироваться в зависимости от используемого языка (как, например, в [Toldova, Ionov 2016](https://publications.hse.ru/pubs/share/folder/mdgnhbxaph/199498798.pdf) для русского). Возможные признаки (из Soon et al. 2001):
        - дистанция между элементами пары;
        - грамматические характеристики ИГ-кандитата/анафора: является ли элемент местоимением (+ какого класса), определенность (definiteness, для языков с артиклями)
        - грамматические характеристики пары: согласуются ли они по грамм.признакам (род/число/падеж/одушевленность/...)
        - семантические характеристики: к какому семант.классу относятся ИГ, семант.отношения между ИГ
        - строковые признаки: сопадают ли ИГ полностью или частично, является ли ИГ альтернативным написанием (alias) другой ИГ
    
        В качестве алгоритма ML используется дерево решений.


    SOTA: тут я затрудняюсь ответить однозначно, так как я встретила разную информацию. В [Liu, Mao, Luu, et al. 2023](https://sentic.net/survey-on-coreference-resolution.pdf) и на [nlpprogress](http://nlpprogress.com/english/coreference_resolution.html) приводятся разные SOTA-модели в зависимости от используемых датасетов. Например, в рамках CoNLL-2012 Shared Task по данным nlpprogress сейчас SOTA — модель wl-coref (word-level coreference resolution model) [Dobrovolskii 2021](https://github.com/vdobrovolskii/wl-coref?tab=readme-ov-file#citation), в статье [Liu, Mao, Luu, et al. 2023] в качестве SOTA упоминается end-to-end модель [Wang et al. 2021](https://ieeexplore.ieee.org/document/9413579). Также высокие результаты показывают BERT модели.

    С течением времени исследования в области разрешения кореферентности перешли от правиловых подходов и классического машинного обучения к разработке нейронных сетей и методам глубокого обучения, которые позволяют учитывать более широкие контексты информации для более точного установления кореферентных связей. В рамках глубокого обучения все более высокие результаты показывают предобученные модели, основанные на трнасформерах. 


### Задание 4 (15 баллов). 

Возьмите любой достаточно большой conll-файл и проведите мини-исследование, связанное с дативно-предикативными конструкциями (такими, как "мне холодно" и "сегодня холодно": предикативы такого рода могут присоединять дополнение в дат.п., а могут не присоединять), по [статье](https://www.dialog-21.ru/media/5937/zimmerlingav120.pdf) А.В. Циммерлинга. Вам понадобится написать скрипт, в котором будут автоматически рассчитываться метрики, приведенные Циммерлингом в своей статье. Придется учесть, что в формате UD нет части речи "предикатив" (можно посчитать метрики только для n верхних предикативов в его таблице - это будут конкретные слова), и подумать о том, как собирать все зависимые для текущего проверяемого токена. Советую взять Синтагрус (либо можно разобрать свои собственные тексты, но если будет их слишком мало, у вас метрики будут близки к нулю или просто нули). Для части группы, которая умеет писать код в классах, настойчиво советую оформить это в класс. 
